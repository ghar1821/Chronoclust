"""
Script will calculate amount of time used for clustering based on Chronoclust log file
"""

import re

from datetime import datetime


def get_clustering_time(log_file):
    """
    Get the total time taken for clustering a dataset.
    :param log_file: log file generated by chronoclust
    :return: clustering time in hours
    """

    with open(log_file, 'r') as f:
        data = f.read().replace('\n', '')

    start_time = get_start_time(data).group(0)

    end_time = get_end_time(data).group(0)

    time_diff = calculate_time_difference(start_time, end_time)

    return time_diff


def get_clustering_time_per_day(log_file):
    """
    Get the time taken to cluster each day's dataset.
    :param log_file: log file generated by chronoclust
    :return: clustering time in hours per day as dictionary.
    """

    with open(log_file, 'r') as f:
        data = f.read().replace('\n', '')

    start_times = get_start_each_day(data)

    end_times = get_end_each_day(data)

    duration = {}
    for day in start_times.keys():
        start_time = start_times.get(day)
        end_time = end_times.get(day)

        time_diff = calculate_time_difference(start_time, end_time)

        duration[day] = time_diff

    return duration


def get_end_time(data):
    chrono_end_line = re.search('\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} \[INFO    \] Chronoclust finish', data).group(0)

    # extract timestamp such as: 2018-12-14 23:53:26,233
    match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}', chrono_end_line)

    return match


def get_start_time(data):
    chrono_start_line = re.search('.*Chronoclust start', data).group(0)
    # extract timestamp such as: 2018-12-14 23:53:26,233
    match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}', chrono_start_line)
    if match is None:
        # For backwards compatibility where chronoclust start has no timestamp. Stupid!
        scaler_line = re.search('.*Setting up scaler', data).group(0)

        # extract timestamp such as: 2018-12-14 23:53:26,233
        match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}', scaler_line)
    return match


def calculate_time_difference(start, end):
    fmt = '%Y-%m-%d %H:%M:%S'

    # Remove the microseconds. Not needed.
    tstamp1 = datetime.strptime(start.split(",")[0], fmt)
    tstamp2 = datetime.strptime(end.split(",")[0], fmt)

    if tstamp1 > tstamp2:
        td = tstamp1 - tstamp2
    else:
        td = tstamp2 - tstamp1
    td_hours = td.total_seconds() / 3600

    return td_hours


def get_start_each_day(data):
    """
    From log file, get the start time of clustering for each day
    :param data: log data
    :return: start time per day as dictionary {day: start_time}
    """
    start = {}
    for i in range(8):
        chrono_end_line = re.search('\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} \[INFO    \] '
                                    'Starting online microcluster maintenance for timepoint ' + str(i), data).group(0)

        # extract timestamp such as: 2018-12-14 23:53:26,233
        match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}', chrono_end_line)

        # extract day
        start[i] = match.group(0)

    return start


def get_end_each_day(data):
    """
    From log file, get the end time of clustering for each day
    :param data: log data
    :return: end time per day as dictionary {day: end_time}
    """
    end = {}
    for i in range(8):
        chrono_end_line = re.search('\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} \[INFO    \] '
                                    'Finish offline clustering for dataset with timepoint: ' + str(i), data).group(0)

        # extract timestamp such as: 2018-12-14 23:53:26,233
        match = re.search(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}', chrono_end_line)

        # extract day
        end[i] = match.group(0)

    return end



